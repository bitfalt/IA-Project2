{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.transforms import Resize, InterpolationMode\n",
    "import torchaudio\n",
    "from torchsummary import summary\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "from torchaudio.transforms import MelSpectrogram, FrequencyMasking\n",
    "import librosa\n",
    "import wandb\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "from os import listdir, scandir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectogram(specgram, title=None, ylabel='freq_bin'):\n",
    "    _, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.imshow(librosa.power_to_db(specgram), origin='lower', aspect='auto')\n",
    "\n",
    "def plot_history(history, net_name):\n",
    "    x_ticks = range(1, len(history['train']['loss']) + 1)\n",
    "    for item in history['train'].keys():\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        for prefix, color in zip(['train', 'val'], ['r', 'b']):\n",
    "            plt.plot(x_ticks, history[prefix][item], c=color, alpha=0.75, linestyle='--',\n",
    "                     label=prefix)\n",
    "        plt.title('{} {}'.format(net_name, item))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.xticks(x_ticks)\n",
    "        plt.ylabel(item)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_metric_values(metric_values, net_name):\n",
    "    for item in metric_values:\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))\n",
    "        x = range(metric_values[item].shape[0])\n",
    "        mean = metric_values[item].mean()\n",
    "        bars = ax.bar(x, metric_values[item])\n",
    "        \n",
    "        ax.axhline(mean, color='r', linestyle=':')\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            \n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, height, '{:.2}'.format(height),\n",
    "                    ha='center', va='bottom')\n",
    "        ax.set_xlabel('Class')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_title('{} {} on test'.format(net_name, item))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_audio</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/59/7_59_29.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/59/7_59_15.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/59/2_59_1.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/59/3_59_1.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/59/9_59_22.wav</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>../data/25/5_25_27.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>../data/25/5_25_33.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>../data/25/7_25_2.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>../data/25/6_25_2.wav</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>../data/25/6_25_13.wav</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                path_to_audio  class\n",
       "0      ../data/59/7_59_29.wav      7\n",
       "1      ../data/59/7_59_15.wav      7\n",
       "2       ../data/59/2_59_1.wav      2\n",
       "3       ../data/59/3_59_1.wav      3\n",
       "4      ../data/59/9_59_22.wav      9\n",
       "...                       ...    ...\n",
       "29995  ../data/25/5_25_27.wav      5\n",
       "29996  ../data/25/5_25_33.wav      5\n",
       "29997   ../data/25/7_25_2.wav      7\n",
       "29998   ../data/25/6_25_2.wav      6\n",
       "29999  ../data/25/6_25_13.wav      6\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workdir_path = Path('../data')\n",
    "sample_rate = 48000\n",
    "\n",
    "data = []\n",
    "with scandir(workdir_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            path_to_dir = workdir_path / entry.name\n",
    "\n",
    "            for filename in listdir(path_to_dir):\n",
    "                path_to_audio = path_to_dir / filename\n",
    "\n",
    "                data.append((path_to_audio, int(filename[0])))\n",
    "\n",
    "audio_df = pd.DataFrame(data, columns=['path_to_audio', 'class'])\n",
    "\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 classes in the dataset\n"
     ]
    }
   ],
   "source": [
    "n_classes = audio_df['class'].max() + 1\n",
    "print(f'There are {n_classes} classes in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1\n",
    "n_mels = 24\n",
    "time = 48\n",
    "\n",
    "transform = torch.nn.Sequential(\n",
    "    MelSpectrogram(sample_rate, n_fft=1024, n_mels=n_mels),\n",
    "    Resize(size=(n_mels, time), interpolation=InterpolationMode.NEAREST)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_masking.shape: torch.Size([1, 24, 48]), sample_masking.class: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RawAudioDatasetFreqMasking(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.freq_mask = FrequencyMasking(freq_mask_param=7)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path_to_audio, class_label = self.df.iloc[i]\n",
    "        waveform, _ = torchaudio.load(path_to_audio, normalize=True)\n",
    "\n",
    "        specgram = self.transform(waveform)\n",
    "        specgram = self.freq_mask(specgram)\n",
    "\n",
    "        return specgram, class_label, path_to_audio\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "ds = RawAudioDatasetFreqMasking(audio_df, transform)\n",
    "sample_masking = ds[0]\n",
    "plot_spectogram(sample_masking[0][0], 'Mel Spectogram')\n",
    "print(f'sample_masking.shape: {sample_masking[0].shape}, sample_masking.class: {sample_masking[1]}')\n",
    "plt.savefig('sample_masking.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed dataset to /Users/bitfalt/Developer/IA-Project2/notebooks/RawWithDataAugmentation\n",
      "Total items to process: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing and Saving: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30000/30000 [01:15<00:00, 399.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset saving complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def save_processed_dataset(dataset: RawAudioDatasetFreqMasking, output_base_dir: str):\n",
    "    \"\"\"\n",
    "    Processes each item in the dataset and saves the resulting spectrogram tensor\n",
    "    to files organized by class label and original filename.\n",
    "\n",
    "    Args:\n",
    "        dataset: An instance of RawAudioDataset.\n",
    "        output_base_dir: The base directory where the processed data will be saved.\n",
    "                         E.g., 'RawFreqMasking'.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Saving processed dataset to {os.path.abspath(output_base_dir)}\")\n",
    "    print(f\"Total items to process: {len(dataset)}\")\n",
    "\n",
    "    # Iterate through the dataset using tqdm for a progress bar\n",
    "    # Accessing items via index calls the __getitem__ method\n",
    "    for i in tqdm(range(len(dataset)), desc=\"Processing and Saving\"):\n",
    "        item = dataset[i]\n",
    "\n",
    "        # Check if item is valid (in case of errors handled in __getitem__)\n",
    "        if item[0] is None:\n",
    "            continue # Skip this item if there was an error\n",
    "\n",
    "        specgram, class_label, original_path = item\n",
    "\n",
    "        # Create the class subdirectory\n",
    "        # Use str(class_label) to handle potential numeric labels\n",
    "        class_output_dir = os.path.join(output_base_dir, str(class_label))\n",
    "        os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "        # Generate the output filename based on the original filename\n",
    "        original_filename = os.path.basename(original_path) # e.g., '0_59_29.wav'\n",
    "        filename_base, _ = os.path.splitext(original_filename) # e.g., '0_59_29'\n",
    "        output_filename = f\"{filename_base}.pt\" # Save as a PyTorch tensor file\n",
    "\n",
    "        # Create the full path to save the file\n",
    "        save_path = os.path.join(class_output_dir, output_filename)\n",
    "\n",
    "        # Save the spectrogram tensor\n",
    "        try:\n",
    "            torch.save(specgram, save_path)\n",
    "        except Exception as e:\n",
    "             print(f\"\\nError saving {save_path}: {e}\") # Print newline to not mess with tqdm bar\n",
    "\n",
    "\n",
    "    print(\"\\nDataset saving complete.\")\n",
    "\n",
    "save_processed_dataset(ds, 'RawWithDataAugmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(ds, [0.7, 0.15, 0.15])\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size)\n",
    "test_dl = DataLoader(test_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model A (LeNet5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Sequential):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super().__init__(\n",
    "            torch.nn.Conv2d(in_channels=n_channels, out_channels=6, kernel_size=5),\n",
    "            torch.nn.AvgPool2d(kernel_size=2),\n",
    "            torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            torch.nn.AvgPool2d(kernel_size=2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features=432, out_features=120),\n",
    "            torch.nn.Linear(in_features=120, out_features=84),\n",
    "            torch.nn.Linear(in_features=84, out_features=n_classes)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet5(n_channels=n_channels, n_classes=n_classes)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "\n",
    "summary(net, (n_channels, n_mels, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    entity=\"bitfalt-itcr\",\n",
    "    project=\"test-wandb\",\n",
    "    config={\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    tags=[\"Model A\", \"LeNet5\", \"MNIST Audio\", \"Raw\", \"With Data Augmentation\"],\n",
    "    notes=\"Run with test and val metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, eval_dl, prefix, criterion, metrics, device):\n",
    "    eval_loss = torch.tensor(0.0).to(device)\n",
    "    eval_metric_values = {\n",
    "        metric: torch.zeros(metrics[metric].num_classes if metrics[metric].average is None\n",
    "                            else 1).to(device) for metric in metrics\n",
    "    }\n",
    "    \n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in eval_dl:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            preds = net(X)\n",
    "            loss = criterion(preds, y)\n",
    "            \n",
    "            eval_loss += loss.detach().cpu() * eval_dl.batch_size\n",
    "            for metric in metrics:\n",
    "                eval_metric_values[metric] += metrics[metric](preds, y) * \\\n",
    "                    eval_dl.batch_size\n",
    "    \n",
    "    eval_loss /= len(eval_dl.dataset)\n",
    "    for metric in metrics:\n",
    "        eval_metric_values[metric] /= len(eval_dl.dataset)\n",
    "    \n",
    "    print('{}_loss: {:.3f}'.format(prefix, eval_loss), end='')\n",
    "    for metric in metrics:\n",
    "        print(', {}_{}: {:.3f}'.format(prefix, metric, eval_metric_values[metric].mean()),\n",
    "              end='')\n",
    "        \n",
    "        if prefix == 'test':\n",
    "            lossKey = f\"{prefix} Loss\"\n",
    "            metricKey = f\"{prefix} {metric}\"\n",
    "            wandb.log({\n",
    "                lossKey: eval_loss,\n",
    "                metricKey: eval_metric_values[metric].mean(),\n",
    "            })\n",
    "    \n",
    "    return eval_loss, eval_metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_dl, val_dl, n_epochs, criterion, metrics, device, lr):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    history = {\n",
    "        'train': {'loss': []} | {metric: [] for metric in metrics},\n",
    "        'val': {'loss': []} | {metric: [] for metric in metrics}\n",
    "    }\n",
    "    \n",
    "    net.to(device)\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = torch.tensor(0.0).to(device)\n",
    "        train_metric_values = {\n",
    "            metric: torch.tensor(0.0).to(device) for metric in metrics\n",
    "        }\n",
    "        \n",
    "        net.train()\n",
    "        for X, y in tqdm(train_dl, desc='Epoch {}/{}'.format(epoch + 1, n_epochs),\n",
    "                         total=len(train_dl)):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            preds = net(X)\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                train_loss += loss.detach().cpu() * train_dl.batch_size\n",
    "                for metric in metrics:\n",
    "                    train_metric_values[metric] += train_dl.batch_size * \\\n",
    "                        metrics[metric](preds, y)\n",
    "        \n",
    "        train_loss /= len(train_dl.dataset)\n",
    "        for metric in metrics:\n",
    "            train_metric_values[metric] /= len(train_dl.dataset)\n",
    "        \n",
    "        print('train_loss: {:.3f}'.format(train_loss), end=', ')\n",
    "        for metric in metrics:\n",
    "            print('train_{}: {:.3f}'.format(metric, train_metric_values[metric]),\n",
    "                  end=', ')\n",
    "\n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch,\n",
    "                \"Train Loss\": train_loss,\n",
    "                \"Train \" + metric: train_metric_values[metric],\n",
    "            })\n",
    "        \n",
    "        history['train']['loss'].append(train_loss.cpu().detach().numpy().item())\n",
    "        for metric in metrics:\n",
    "            history['train'][metric].append(train_metric_values[metric].cpu().detach() \\\n",
    "                                            .numpy().item())\n",
    "            \n",
    "        val_loss, val_metric_values = eval(net, val_dl, prefix='val', criterion=criterion,\n",
    "                                           metrics=metrics, device=device)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        history['val']['loss'].append(val_loss.cpu().detach().numpy().item())\n",
    "        for metric in metrics:\n",
    "            history['val'][metric].append(val_metric_values[metric].cpu().detach() \\\n",
    "                                          .numpy().item())\n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch,\n",
    "                \"Val Loss\": val_loss,\n",
    "                \"Val \" + metric: val_metric_values[metric],\n",
    "            })\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_metrics = {\n",
    "    'accuracy': Accuracy(task='multiclass', num_classes=int(n_classes),\n",
    "                         average='macro').to(device),\n",
    "    'precision': Precision(task='multiclass', num_classes=int(n_classes),\n",
    "                           average='macro').to(device),\n",
    "    'recall': Recall(task='multiclass', num_classes=int(n_classes),\n",
    "                     average='macro').to(device),\n",
    "    'f1-score': F1Score(task='multiclass', num_classes=int(n_classes),\n",
    "                        average='macro').to(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(net, train_dl, val_dl, n_epochs=15, criterion=criterion,\n",
    "                metrics=train_metrics, device=device, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, net_name='LeNet5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {\n",
    "    'accuracy': Accuracy(task='multiclass', num_classes=int(n_classes),\n",
    "                         average=None).to(device),\n",
    "    'precision': Precision(task='multiclass', num_classes=int(n_classes),\n",
    "                           average=None).to(device),\n",
    "    'recall': Recall(task='multiclass', num_classes=int(n_classes),\n",
    "                     average=None).to(device),\n",
    "    'f1-score': F1Score(task='multiclass', num_classes=int(n_classes),\n",
    "                        average=None).to(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_metric_values = eval(net, test_dl, prefix='test', criterion=criterion,\n",
    "                             metrics=test_metrics, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_values(test_metric_values, net_name='LeNet5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
