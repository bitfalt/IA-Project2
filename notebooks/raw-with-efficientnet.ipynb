{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation con Datos Raw y EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.transforms import Resize, InterpolationMode\n",
    "import torchaudio\n",
    "import librosa\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from os import listdir, scandir\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Importaciones adicionales para EfficientNet\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torchsummary import summary\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate, title=None):\n",
    "    waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "    \n",
    "    figure, axes = plt.subplots(num_channels, 1, figsize=(12, 4))\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    \n",
    "    figure.suptitle(title or 'Waveform')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir_path = Path('../data')\n",
    "sample_rate = 48000\n",
    "\n",
    "data = []\n",
    "with scandir(workdir_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            path_to_dir = workdir_path / entry.name\n",
    "\n",
    "            for filename in listdir(path_to_dir):\n",
    "                path_to_audio = path_to_dir / filename\n",
    "\n",
    "                data.append((path_to_audio, int(filename[0])))\n",
    "\n",
    "audio_df = pd.DataFrame(data, columns=['path_to_audio', 'class'])\n",
    "\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = audio_df['class'].max() + 1\n",
    "print(f'There are {n_classes} classes in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset with Raw Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para EfficientNet con datos raw\n",
    "n_channels = 3  # EfficientNet requiere 3 canales\n",
    "n_mels = 224    # Tamaño estándar para EfficientNet\n",
    "time = 224      # Tamaño estándar para EfficientNet\n",
    "\n",
    "# Longitud máxima de la forma de onda (en muestras)\n",
    "max_length = 48000  # 1 segundo a 48kHz\n",
    "\n",
    "# Transformación para redimensionar\n",
    "resize_transform = Resize(size=(n_mels, time), interpolation=InterpolationMode.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawAudioDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_sample_path = self.df.iloc[idx, 0]\n",
    "        class_id = self.df.iloc[idx, 1]\n",
    "        \n",
    "        # Cargar archivo de audio\n",
    "        waveform, sample_rate = torchaudio.load(audio_sample_path)\n",
    "        \n",
    "        # Asegurar que la forma de onda tenga la longitud correcta\n",
    "        if waveform.size(1) < max_length:\n",
    "            # Padding si es más corto\n",
    "            padding = torch.zeros(1, max_length - waveform.size(1))\n",
    "            waveform = torch.cat([waveform, padding], dim=1)\n",
    "        elif waveform.size(1) > max_length:\n",
    "            # Recortar si es más largo\n",
    "            waveform = waveform[:, :max_length]\n",
    "        \n",
    "        # Normalizar la forma de onda\n",
    "        if waveform.abs().max() > 0:\n",
    "            waveform = waveform / waveform.abs().max()\n",
    "        \n",
    "        # Redimensionar para EfficientNet (224x224)\n",
    "        # Primero, reorganizar la forma de onda en una matriz 2D\n",
    "        waveform_2d = waveform.view(1, -1, int(np.sqrt(max_length)), int(np.sqrt(max_length)))\n",
    "        waveform_2d = waveform_2d.squeeze(0)  # Eliminar la primera dimensión\n",
    "        \n",
    "        # Aplicar redimensionamiento\n",
    "        resized_waveform = resize_transform(waveform_2d)\n",
    "        \n",
    "        # Convertir a 3 canales para EfficientNet\n",
    "        # Repetimos el canal para crear una imagen RGB\n",
    "        resized_waveform = resized_waveform.repeat(3, 1, 1)\n",
    "        \n",
    "        return resized_waveform, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset con datos raw\n",
    "audio_dataset = RawAudioDataset(df=audio_df)\n",
    "\n",
    "# Verificar una muestra\n",
    "sample, label = audio_dataset[0]\n",
    "print(audio_df.iloc[0, 0])\n",
    "print(f'sample.shape: {sample.shape}, sample.class: {label}')\n",
    "\n",
    "# Visualizar la muestra\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(sample[0].numpy(), aspect='auto')\n",
    "plt.title('Datos Raw redimensionados')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en entrenamiento y validación\n",
    "train_size = int(0.8 * len(audio_dataset))\n",
    "val_size = len(audio_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(audio_dataset, [train_size, val_size])\n",
    "\n",
    "print(f'Training set size: {len(train_dataset)}')\n",
    "print(f'Validation set size: {len(val_dataset)}')\n",
    "\n",
    "# Crear dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioEfficientNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(AudioEfficientNet, self).__init__()\n",
    "        \n",
    "        # Cargar modelo pre-entrenado EfficientNet-B0\n",
    "        self.efficientnet = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        \n",
    "        # Modificar la última capa para nuestro número de clases\n",
    "        in_features = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier[1] = nn.Linear(in_features, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay GPU disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear modelo\n",
    "model = AudioEfficientNet(n_classes=int(n_classes))\n",
    "model = model.to(device)\n",
    "\n",
    "# Mostrar resumen del modelo\n",
    "summary(model, (3, n_mels, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir métricas\n",
    "accuracy = Accuracy(task='multiclass', num_classes=int(n_classes)).to(device)\n",
    "precision = Precision(task='multiclass', num_classes=int(n_classes), average='macro').to(device)\n",
    "recall = Recall(task='multiclass', num_classes=int(n_classes), average='macro').to(device)\n",
    "f1 = F1Score(task='multiclass', num_classes=int(n_classes), average='macro').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar el modelo\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_acc += accuracy(outputs, labels) * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_acc / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar el modelo\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_precision = 0.0\n",
    "    running_recall = 0.0\n",
    "    running_f1 = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_acc += accuracy(outputs, labels) * inputs.size(0)\n",
    "            running_precision += precision(outputs, labels) * inputs.size(0)\n",
    "            running_recall += recall(outputs, labels) * inputs.size(0)\n",
    "            running_f1 += f1(outputs, labels) * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_acc / len(dataloader.dataset)\n",
    "    epoch_precision = running_precision / len(dataloader.dataset)\n",
    "    epoch_recall = running_recall / len(dataloader.dataset)\n",
    "    epoch_f1 = running_f1 / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "num_epochs = 10\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_precision': [],\n",
    "    'val_recall': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_precision, val_recall, val_f1 = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_precision'].append(val_precision)\n",
    "    history['val_recall'].append(val_recall)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}')\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las métricas\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizar métricas adicionales\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['val_precision'], label='Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['val_recall'], label='Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['val_f1'], label='F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), '../models/efficientnet_raw.pth')\n",
    "print('Modelo guardado correctamente')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}