{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation con Filtro Bilateral y EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.transforms import Resize, InterpolationMode\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "import librosa\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from os import listdir, scandir\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Importaciones adicionales para EfficientNet\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torchsummary import summary\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectogram(specgram, title=None, ylabel='freq_bin'):\n",
    "    _, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.imshow(librosa.power_to_db(specgram), origin='lower', aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir_path = Path('../data')\n",
    "sample_rate = 48000\n",
    "\n",
    "data = []\n",
    "with scandir(workdir_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            path_to_dir = workdir_path / entry.name\n",
    "\n",
    "            for filename in listdir(path_to_dir):\n",
    "                path_to_audio = path_to_dir / filename\n",
    "\n",
    "                data.append((path_to_audio, int(filename[0])))\n",
    "\n",
    "audio_df = pd.DataFrame(data, columns=['path_to_audio', 'class'])\n",
    "\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = audio_df['class'].max() + 1\n",
    "print(f'There are {n_classes} classes in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset with Bilateral Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para EfficientNet con filtro bilateral\n",
    "n_channels = 3  # EfficientNet requiere 3 canales\n",
    "n_mels = 224    # Tamaño estándar para EfficientNet\n",
    "time = 224      # Tamaño estándar para EfficientNet\n",
    "\n",
    "# Transformación base (espectrograma)\n",
    "base_transform = torch.nn.Sequential(\n",
    "    MelSpectrogram(sample_rate, n_fft=1024, n_mels=64),\n",
    "    Resize(size=(n_mels, time), interpolation=InterpolationMode.BICUBIC)\n",
    ")\n",
    "\n",
    "# Parámetros para el filtro bilateral\n",
    "d = 9  # Diámetro de cada pixel vecino que será usado durante el filtrado\n",
    "sigma_color = 75  # Sigma del espacio de color\n",
    "sigma_space = 75  # Sigma del espacio de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDatasetBilateral(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_sample_path = self.df.iloc[idx, 0]\n",
    "        class_id = self.df.iloc[idx, 1]\n",
    "        \n",
    "        # Cargar archivo de audio\n",
    "        waveform, sample_rate = torchaudio.load(audio_sample_path)\n",
    "        \n",
    "        # Aplicar transformación (convertir a espectrograma)\n",
    "        if self.transform:\n",
    "            spectrogram = self.transform(waveform)\n",
    "            \n",
    "            # Convertir a numpy para aplicar filtro bilateral\n",
    "            spec_np = spectrogram.squeeze().numpy()\n",
    "            \n",
    "            # Normalizar para visualización (0-255)\n",
    "            if spec_np.max() > 0:\n",
    "                spec_np = (spec_np / spec_np.max() * 255).astype(np.uint8)\n",
    "            \n",
    "            # Aplicar filtro bilateral\n",
    "            bilateral_spec = cv2.bilateralFilter(spec_np, d, sigma_color, sigma_space)\n",
    "            \n",
    "            # Convertir de vuelta a tensor\n",
    "            bilateral_spec = torch.from_numpy(bilateral_spec).float()\n",
    "            bilateral_spec = bilateral_spec.unsqueeze(0)  # Añadir dimensión de canal\n",
    "            \n",
    "            # Convertir a 3 canales para EfficientNet\n",
    "            # Repetimos el canal para crear una imagen RGB\n",
    "            bilateral_spec = bilateral_spec.repeat(3, 1, 1)\n",
    "            \n",
    "            # Normalizar valores entre 0 y 1\n",
    "            if bilateral_spec.max() > 0:\n",
    "                bilateral_spec = bilateral_spec / bilateral_spec.max()\n",
    "            \n",
    "            return bilateral_spec, class_id\n",
    "        \n",
    "        return None, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset con filtro bilateral\n",
    "audio_dataset = AudioDatasetBilateral(df=audio_df, transform=base_transform)\n",
    "\n",
    "# Verificar una muestra\n",
    "sample, label = audio_dataset[0]\n",
    "print(audio_df.iloc[0, 0])\n",
    "print(f'sample.shape: {sample.shape}, sample.class: {label}')\n",
    "\n",
    "# Visualizar el espectrograma con filtro bilateral\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(sample[0].numpy(), aspect='auto', origin='lower')\n",
    "plt.title('Espectrograma con filtro bilateral')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en entrenamiento y validación\n",
    "train_size = int(0.8 * len(audio_dataset))\n",
    "val_size = len(audio_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(audio_dataset, [train_size, val_size])\n",
    "\n",
    "print(f'Training set size: {len(train_dataset)}')\n",
    "print(f'Validation set size: {len(val_dataset)}')\n",
    "\n",
    "# Crear dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioEfficientNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(AudioEfficientNet, self).__init__()\n",
    "        \n",
    "        # Cargar modelo pre-entrenado EfficientNet-B0\n",
    "        self.efficientnet = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        \n",
    "        # Modificar la última capa para nuestro número de clases\n",
    "        in_features = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier[1] = nn.Linear(in_features, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay GPU disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear modelo\n",
    "model = AudioEfficientNet(n_classes=int(n_classes))\n",
    "model = model.to(device)\n",
    "\n",
    "# Mostrar resumen del modelo\n",
    "summary(model, (3, n_mels, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir métricas\n",
    "accuracy = Accuracy(task='multiclass', num_classes=int(n_classes)).to(device)\n",
    "precision = Precision(task='multiclass', num_classes=int(n_classes), average='macro').to(device)\n",
    "recall = Recall(task='multiclass', num_classes=int(n_classes), average='macro').to(device)\n",
    "f1 = F1Score(task='multiclass', num_classes=int(n_classes), average='macro').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar el modelo\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_acc += accuracy(outputs, labels) * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_acc / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar el modelo\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_precision = 0.0\n",
    "    running_recall = 0.0\n",
    "    running_f1 = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_acc += accuracy(outputs, labels) * inputs.size(0)\n",
    "            running_precision += precision(outputs, labels) * inputs.size(0)\n",
    "            running_recall += recall(outputs, labels) * inputs.size(0)\n",
    "            running_f1 += f1(outputs, labels) * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_acc / len(dataloader.dataset)\n",
    "    epoch_precision = running_precision / len(dataloader.dataset)\n",
    "    epoch_recall = running_recall / len(dataloader.dataset)\n",
    "    epoch_f1 = running_f1 / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "num_epochs = 10\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_precision': [],\n",
    "    'val_recall': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_precision, val_recall, val_f1 = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_precision'].append(val_precision)\n",
    "    history['val_recall'].append(val_recall)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}')\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las métricas\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizar métricas adicionales\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['val_precision'], label='Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['val_recall'], label='Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['val_f1'], label='F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), '../models/efficientnet_bilateral.pth')\n",
    "print('Modelo guardado correctamente')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}